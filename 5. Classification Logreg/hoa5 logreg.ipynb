{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9100cc6-d66d-4fbe-9c33-0edad2e2268b",
   "metadata": {},
   "source": [
    "Nama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e99bf4bc-a09c-40ee-88df-8d195696479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanun Masitha Ramadhani\n"
     ]
    }
   ],
   "source": [
    "print(\"Hanun Masitha Ramadhani\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc5cb6-bf6e-4ac3-8dae-53b070dd197d",
   "metadata": {},
   "source": [
    "(1) Gunakan X_train_final, X_test_final, y_train, dan y_test yang telah Anda buat pada HOA-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5a5e2a-6f7c-4965-b84e-03e2f63fc9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>Age</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>41</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>49</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>33</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>27</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>2935</td>\n",
       "      <td>2936</td>\n",
       "      <td>No</td>\n",
       "      <td>36</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>884</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>Medical</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>2936</td>\n",
       "      <td>2937</td>\n",
       "      <td>No</td>\n",
       "      <td>39</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>613</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>2937</td>\n",
       "      <td>2938</td>\n",
       "      <td>No</td>\n",
       "      <td>27</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>155</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>2938</td>\n",
       "      <td>2939</td>\n",
       "      <td>No</td>\n",
       "      <td>49</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1023</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>2939</td>\n",
       "      <td>2940</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>628</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2940 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  EmployeeNumber Attrition  Age     BusinessTravel  DailyRate  \\\n",
       "0              0               1       Yes   41      Travel_Rarely       1102   \n",
       "1              1               2        No   49  Travel_Frequently        279   \n",
       "2              2               3       Yes   37      Travel_Rarely       1373   \n",
       "3              3               4        No   33  Travel_Frequently       1392   \n",
       "4              4               5        No   27      Travel_Rarely        591   \n",
       "...          ...             ...       ...  ...                ...        ...   \n",
       "2935        2935            2936        No   36  Travel_Frequently        884   \n",
       "2936        2936            2937        No   39      Travel_Rarely        613   \n",
       "2937        2937            2938        No   27      Travel_Rarely        155   \n",
       "2938        2938            2939        No   49  Travel_Frequently       1023   \n",
       "2939        2939            2940        No   34      Travel_Rarely        628   \n",
       "\n",
       "                  Department  DistanceFromHome  Education EducationField  ...  \\\n",
       "0                      Sales                 1          2  Life Sciences  ...   \n",
       "1     Research & Development                 8          1  Life Sciences  ...   \n",
       "2     Research & Development                 2          2          Other  ...   \n",
       "3     Research & Development                 3          4  Life Sciences  ...   \n",
       "4     Research & Development                 2          1        Medical  ...   \n",
       "...                      ...               ...        ...            ...  ...   \n",
       "2935  Research & Development                23          2        Medical  ...   \n",
       "2936  Research & Development                 6          1        Medical  ...   \n",
       "2937  Research & Development                 4          3  Life Sciences  ...   \n",
       "2938                   Sales                 2          3        Medical  ...   \n",
       "2939  Research & Development                 8          3        Medical  ...   \n",
       "\n",
       "      RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0                            1            80                 0   \n",
       "1                            4            80                 1   \n",
       "2                            2            80                 0   \n",
       "3                            3            80                 0   \n",
       "4                            4            80                 1   \n",
       "...                        ...           ...               ...   \n",
       "2935                         3            80                 1   \n",
       "2936                         1            80                 1   \n",
       "2937                         2            80                 1   \n",
       "2938                         4            80                 0   \n",
       "2939                         1            80                 0   \n",
       "\n",
       "      TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                     8                      0               1   \n",
       "1                    10                      3               3   \n",
       "2                     7                      3               3   \n",
       "3                     8                      3               3   \n",
       "4                     6                      3               3   \n",
       "...                 ...                    ...             ...   \n",
       "2935                 17                      3               3   \n",
       "2936                  9                      5               3   \n",
       "2937                  6                      0               3   \n",
       "2938                 17                      3               2   \n",
       "2939                  6                      3               4   \n",
       "\n",
       "      YearsAtCompany YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0                  6                  4                        0   \n",
       "1                 10                  7                        1   \n",
       "2                  0                  0                        0   \n",
       "3                  8                  7                        3   \n",
       "4                  2                  2                        2   \n",
       "...              ...                ...                      ...   \n",
       "2935               5                  2                        0   \n",
       "2936               7                  7                        1   \n",
       "2937               6                  2                        0   \n",
       "2938               9                  6                        0   \n",
       "2939               4                  3                        1   \n",
       "\n",
       "      YearsWithCurrManager  \n",
       "0                        5  \n",
       "1                        7  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        2  \n",
       "...                    ...  \n",
       "2935                     3  \n",
       "2936                     7  \n",
       "2937                     3  \n",
       "2938                     8  \n",
       "2939                     2  \n",
       "\n",
       "[2940 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_employee = pd.read_csv('employee_missing.csv')\n",
    "df_employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indirect-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employee = df_employee.drop([\"Over18\", 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blank-orchestra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation on MonthlyIncome\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre: mean: 6466.2209208400645, std: 4688.835392731094\n",
      "post: mean: 6480.670068027211, std: 4383.015346864026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "employee_number = df_employee.select_dtypes(include = 'number')\n",
    "\n",
    "imputer_knn = KNNImputer(n_neighbors=5)\n",
    "imputer_result = imputer_knn.fit_transform(employee_number)\n",
    "\n",
    "imputer_result = pd.DataFrame(imputer_result)\n",
    "imputer_result.columns = employee_number.columns\n",
    "\n",
    "print(\"imputation on MonthlyIncome\")\n",
    "\n",
    "sns.histplot(employee_number['MonthlyIncome'], alpha=0.2, kde=True)\n",
    "sns.histplot(imputer_result['MonthlyIncome'], alpha=0.2, kde=True, color='red')\n",
    "plt.legend(['pre', 'post'])\n",
    "plt.show()\n",
    "print('pre: mean: {}, std: {}'.format(np.mean(employee_number['MonthlyIncome']), \n",
    "                                      np.std(employee_number['MonthlyIncome'])))\n",
    "print('post: mean: {}, std: {}'.format(np.mean(imputer_result['MonthlyIncome']), \n",
    "                                      np.std(imputer_result['MonthlyIncome'])))\n",
    "\n",
    "sscaler = StandardScaler()\n",
    "scaler_result = sscaler.fit_transform(imputer_result)\n",
    "\n",
    "scaler_result = pd.DataFrame(scaler_result)\n",
    "scaler_result.columns = employee_number.columns\n",
    "\n",
    "employee_number = scaler_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intimate-accident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation on JobRole\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "employee_obj = df_employee.select_dtypes(include = 'object')\n",
    "\n",
    "impute = SimpleImputer(strategy = 'most_frequent')\n",
    "imputer_result = impute.fit_transform(employee_obj)\n",
    "\n",
    "imputer_result = pd.DataFrame(imputer_result)\n",
    "imputer_result.columns = employee_obj.columns\n",
    "\n",
    "print(\"imputation on JobRole\")\n",
    "\n",
    "sns.histplot(employee_obj['JobRole'], alpha=0.2, kde=True)\n",
    "sns.histplot(imputer_result['JobRole'], alpha=0.2, kde=True, color='red')\n",
    "plt.legend(['pre', 'post'])\n",
    "plt.show()\n",
    "\n",
    "oe = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value=np.nan)\n",
    "encoder_result = oe.fit_transform(imputer_result)\n",
    "\n",
    "encoder_result = pd.DataFrame(encoder_result)\n",
    "encoder_result.columns = employee_obj.columns\n",
    "\n",
    "employee_obj = encoder_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "scientific-acquisition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>Age</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>Gender</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>OverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.731462</td>\n",
       "      <td>0.446350</td>\n",
       "      <td>0.742527</td>\n",
       "      <td>-1.010909</td>\n",
       "      <td>-0.891688</td>\n",
       "      <td>-0.660531</td>\n",
       "      <td>1.383138</td>\n",
       "      <td>0.379672</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>1.153254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.679146</td>\n",
       "      <td>0.245834</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.730284</td>\n",
       "      <td>1.322365</td>\n",
       "      <td>-1.297775</td>\n",
       "      <td>-0.147150</td>\n",
       "      <td>-1.868426</td>\n",
       "      <td>0.254625</td>\n",
       "      <td>-0.240677</td>\n",
       "      <td>-1.026167</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>-0.660853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368715</td>\n",
       "      <td>0.806541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.729105</td>\n",
       "      <td>0.008343</td>\n",
       "      <td>1.414363</td>\n",
       "      <td>-0.887515</td>\n",
       "      <td>-0.891688</td>\n",
       "      <td>1.169781</td>\n",
       "      <td>1.284725</td>\n",
       "      <td>-1.026167</td>\n",
       "      <td>-0.961486</td>\n",
       "      <td>0.246200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.679146</td>\n",
       "      <td>-1.155935</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.727927</td>\n",
       "      <td>-0.429664</td>\n",
       "      <td>1.461466</td>\n",
       "      <td>-0.764121</td>\n",
       "      <td>1.061787</td>\n",
       "      <td>1.169781</td>\n",
       "      <td>-0.486709</td>\n",
       "      <td>0.379672</td>\n",
       "      <td>-0.961486</td>\n",
       "      <td>0.246200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252146</td>\n",
       "      <td>-1.155935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.726749</td>\n",
       "      <td>-1.086676</td>\n",
       "      <td>-0.524295</td>\n",
       "      <td>-0.887515</td>\n",
       "      <td>-1.868426</td>\n",
       "      <td>-1.575686</td>\n",
       "      <td>-1.274014</td>\n",
       "      <td>0.379672</td>\n",
       "      <td>-0.961486</td>\n",
       "      <td>-0.660853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058285</td>\n",
       "      <td>-0.595227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>1.726749</td>\n",
       "      <td>-0.101159</td>\n",
       "      <td>0.202082</td>\n",
       "      <td>1.703764</td>\n",
       "      <td>-0.891688</td>\n",
       "      <td>0.254625</td>\n",
       "      <td>-1.224807</td>\n",
       "      <td>1.785511</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>1.153254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.679146</td>\n",
       "      <td>-0.314873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>1.727927</td>\n",
       "      <td>0.227347</td>\n",
       "      <td>-0.469754</td>\n",
       "      <td>-0.393938</td>\n",
       "      <td>-1.868426</td>\n",
       "      <td>1.169781</td>\n",
       "      <td>-1.175601</td>\n",
       "      <td>-1.026167</td>\n",
       "      <td>0.845911</td>\n",
       "      <td>-1.567907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368715</td>\n",
       "      <td>0.806541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>1.729105</td>\n",
       "      <td>-1.086676</td>\n",
       "      <td>-1.605183</td>\n",
       "      <td>-0.640727</td>\n",
       "      <td>0.085049</td>\n",
       "      <td>-0.660531</td>\n",
       "      <td>1.038693</td>\n",
       "      <td>1.785511</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>-0.660853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.679146</td>\n",
       "      <td>-0.314873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>1.730284</td>\n",
       "      <td>1.322365</td>\n",
       "      <td>0.546677</td>\n",
       "      <td>-0.887515</td>\n",
       "      <td>0.085049</td>\n",
       "      <td>1.169781</td>\n",
       "      <td>-0.142264</td>\n",
       "      <td>-1.026167</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>-0.660853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.679146</td>\n",
       "      <td>1.086895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>1.731462</td>\n",
       "      <td>-0.320163</td>\n",
       "      <td>-0.432568</td>\n",
       "      <td>-0.147150</td>\n",
       "      <td>0.085049</td>\n",
       "      <td>-0.660531</td>\n",
       "      <td>0.792660</td>\n",
       "      <td>1.785511</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>0.246200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368715</td>\n",
       "      <td>-0.595227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2940 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EmployeeNumber       Age  DailyRate  DistanceFromHome  Education  \\\n",
       "0          -1.731462  0.446350   0.742527         -1.010909  -0.891688   \n",
       "1          -1.730284  1.322365  -1.297775         -0.147150  -1.868426   \n",
       "2          -1.729105  0.008343   1.414363         -0.887515  -0.891688   \n",
       "3          -1.727927 -0.429664   1.461466         -0.764121   1.061787   \n",
       "4          -1.726749 -1.086676  -0.524295         -0.887515  -1.868426   \n",
       "...              ...       ...        ...               ...        ...   \n",
       "2935        1.726749 -0.101159   0.202082          1.703764  -0.891688   \n",
       "2936        1.727927  0.227347  -0.469754         -0.393938  -1.868426   \n",
       "2937        1.729105 -1.086676  -1.605183         -0.640727   0.085049   \n",
       "2938        1.730284  1.322365   0.546677         -0.887515   0.085049   \n",
       "2939        1.731462 -0.320163  -0.432568         -0.147150   0.085049   \n",
       "\n",
       "      EnvironmentSatisfaction  HourlyRate  JobInvolvement  JobLevel  \\\n",
       "0                   -0.660531    1.383138        0.379672 -0.057788   \n",
       "1                    0.254625   -0.240677       -1.026167 -0.057788   \n",
       "2                    1.169781    1.284725       -1.026167 -0.961486   \n",
       "3                    1.169781   -0.486709        0.379672 -0.961486   \n",
       "4                   -1.575686   -1.274014        0.379672 -0.961486   \n",
       "...                       ...         ...             ...       ...   \n",
       "2935                 0.254625   -1.224807        1.785511 -0.057788   \n",
       "2936                 1.169781   -1.175601       -1.026167  0.845911   \n",
       "2937                -0.660531    1.038693        1.785511 -0.057788   \n",
       "2938                 1.169781   -0.142264       -1.026167 -0.057788   \n",
       "2939                -0.660531    0.792660        1.785511 -0.057788   \n",
       "\n",
       "      JobSatisfaction  ...  YearsSinceLastPromotion  YearsWithCurrManager  \\\n",
       "0            1.153254  ...                -0.679146              0.245834   \n",
       "1           -0.660853  ...                -0.368715              0.806541   \n",
       "2            0.246200  ...                -0.679146             -1.155935   \n",
       "3            0.246200  ...                 0.252146             -1.155935   \n",
       "4           -0.660853  ...                -0.058285             -0.595227   \n",
       "...               ...  ...                      ...                   ...   \n",
       "2935         1.153254  ...                -0.679146             -0.314873   \n",
       "2936        -1.567907  ...                -0.368715              0.806541   \n",
       "2937        -0.660853  ...                -0.679146             -0.314873   \n",
       "2938        -0.660853  ...                -0.679146              1.086895   \n",
       "2939         0.246200  ...                -0.368715             -0.595227   \n",
       "\n",
       "      Attrition  BusinessTravel  Department  EducationField  Gender  JobRole  \\\n",
       "0           1.0             2.0         2.0             1.0     0.0      7.0   \n",
       "1           0.0             1.0         1.0             1.0     1.0      6.0   \n",
       "2           1.0             2.0         1.0             4.0     1.0      2.0   \n",
       "3           0.0             1.0         1.0             1.0     0.0      6.0   \n",
       "4           0.0             2.0         1.0             3.0     1.0      2.0   \n",
       "...         ...             ...         ...             ...     ...      ...   \n",
       "2935        0.0             1.0         1.0             3.0     1.0      2.0   \n",
       "2936        0.0             2.0         1.0             3.0     1.0      0.0   \n",
       "2937        0.0             2.0         1.0             1.0     1.0      4.0   \n",
       "2938        0.0             1.0         2.0             3.0     1.0      7.0   \n",
       "2939        0.0             2.0         1.0             3.0     1.0      2.0   \n",
       "\n",
       "      MaritalStatus  OverTime  \n",
       "0               2.0       1.0  \n",
       "1               1.0       0.0  \n",
       "2               2.0       1.0  \n",
       "3               1.0       1.0  \n",
       "4               1.0       0.0  \n",
       "...             ...       ...  \n",
       "2935            1.0       0.0  \n",
       "2936            1.0       0.0  \n",
       "2937            1.0       1.0  \n",
       "2938            1.0       0.0  \n",
       "2939            1.0       0.0  \n",
       "\n",
       "[2940 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_employee_transformed = pd.concat([employee_number, employee_obj], axis=1)\n",
    "df_employee_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "julian-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_employee_transformed['Attrition']\n",
    "df_employee_transformed = df_employee_transformed.drop([\"Attrition\"], axis=1)\n",
    "X = df_employee_transformed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "disabled-belarus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MonthlyRate</td>\n",
       "      <td>0.134609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DailyRate</td>\n",
       "      <td>0.109042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MonthlyIncome</td>\n",
       "      <td>0.096045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TotalWorkingYears</td>\n",
       "      <td>0.042775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>YearsAtCompany</td>\n",
       "      <td>0.031671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JobLevel</td>\n",
       "      <td>0.028718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>StockOptionLevel</td>\n",
       "      <td>0.026904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>YearsInCurrentRole</td>\n",
       "      <td>0.025730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.025171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>YearsWithCurrManager</td>\n",
       "      <td>0.023764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>JobRole</td>\n",
       "      <td>0.023333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>OverTime</td>\n",
       "      <td>0.021078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WorkLifeBalance</td>\n",
       "      <td>0.017008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MaritalStatus</td>\n",
       "      <td>0.013547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DistanceFromHome</td>\n",
       "      <td>0.012956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EnvironmentSatisfaction</td>\n",
       "      <td>0.012328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HourlyRate</td>\n",
       "      <td>0.011785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>YearsSinceLastPromotion</td>\n",
       "      <td>0.011308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Department</td>\n",
       "      <td>0.010984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EducationField</td>\n",
       "      <td>0.007276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EmployeeNumber</td>\n",
       "      <td>0.006740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NumCompaniesWorked</td>\n",
       "      <td>0.005262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BusinessTravel</td>\n",
       "      <td>0.004336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RelationshipSatisfaction</td>\n",
       "      <td>0.003524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TrainingTimesLastYear</td>\n",
       "      <td>0.002763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JobSatisfaction</td>\n",
       "      <td>0.002587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JobInvolvement</td>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PercentSalaryHike</td>\n",
       "      <td>0.001161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PerformanceRating</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>StandardHours</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    features  mutual_info\n",
       "11               MonthlyRate     0.134609\n",
       "2                  DailyRate     0.109042\n",
       "10             MonthlyIncome     0.096045\n",
       "18         TotalWorkingYears     0.042775\n",
       "21            YearsAtCompany     0.031671\n",
       "8                   JobLevel     0.028718\n",
       "17          StockOptionLevel     0.026904\n",
       "22        YearsInCurrentRole     0.025730\n",
       "1                        Age     0.025171\n",
       "24      YearsWithCurrManager     0.023764\n",
       "29                   JobRole     0.023333\n",
       "31                  OverTime     0.021078\n",
       "20           WorkLifeBalance     0.017008\n",
       "30             MaritalStatus     0.013547\n",
       "3           DistanceFromHome     0.012956\n",
       "5    EnvironmentSatisfaction     0.012328\n",
       "6                 HourlyRate     0.011785\n",
       "23   YearsSinceLastPromotion     0.011308\n",
       "26                Department     0.010984\n",
       "27            EducationField     0.007276\n",
       "0             EmployeeNumber     0.006740\n",
       "12        NumCompaniesWorked     0.005262\n",
       "25            BusinessTravel     0.004336\n",
       "15  RelationshipSatisfaction     0.003524\n",
       "19     TrainingTimesLastYear     0.002763\n",
       "9            JobSatisfaction     0.002587\n",
       "7             JobInvolvement     0.001512\n",
       "13         PercentSalaryHike     0.001161\n",
       "14         PerformanceRating     0.000000\n",
       "28                    Gender     0.000000\n",
       "4                  Education     0.000000\n",
       "16             StandardHours     0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mutual_info_classif(X, y)\n",
    "pd.DataFrame({'features': X.columns, \n",
    "             'mutual_info': mutual_info_classif(X, y)}).sort_values('mutual_info', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "valued-snapshot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>OverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.446350</td>\n",
       "      <td>0.742527</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>-0.111264</td>\n",
       "      <td>0.726020</td>\n",
       "      <td>-0.421642</td>\n",
       "      <td>-0.164613</td>\n",
       "      <td>0.245834</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.322365</td>\n",
       "      <td>-1.297775</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>-0.308160</td>\n",
       "      <td>1.488876</td>\n",
       "      <td>-0.164511</td>\n",
       "      <td>0.488508</td>\n",
       "      <td>0.806541</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008343</td>\n",
       "      <td>1.414363</td>\n",
       "      <td>-0.961486</td>\n",
       "      <td>-1.001746</td>\n",
       "      <td>-1.674841</td>\n",
       "      <td>-0.550208</td>\n",
       "      <td>-1.144294</td>\n",
       "      <td>-1.155935</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.429664</td>\n",
       "      <td>1.461466</td>\n",
       "      <td>-0.961486</td>\n",
       "      <td>0.610751</td>\n",
       "      <td>1.243211</td>\n",
       "      <td>-0.421642</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>-1.155935</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.086676</td>\n",
       "      <td>-0.524295</td>\n",
       "      <td>-0.961486</td>\n",
       "      <td>-0.687351</td>\n",
       "      <td>0.325900</td>\n",
       "      <td>-0.678774</td>\n",
       "      <td>-0.817734</td>\n",
       "      <td>-0.595227</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>-0.101159</td>\n",
       "      <td>0.202082</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>-0.892005</td>\n",
       "      <td>-0.284329</td>\n",
       "      <td>0.735447</td>\n",
       "      <td>-0.327893</td>\n",
       "      <td>-0.314873</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>0.227347</td>\n",
       "      <td>-0.469754</td>\n",
       "      <td>0.845911</td>\n",
       "      <td>0.800894</td>\n",
       "      <td>1.004010</td>\n",
       "      <td>-0.293077</td>\n",
       "      <td>-0.001333</td>\n",
       "      <td>0.806541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>-1.086676</td>\n",
       "      <td>-1.605183</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>-0.544025</td>\n",
       "      <td>-1.284418</td>\n",
       "      <td>-0.678774</td>\n",
       "      <td>-0.164613</td>\n",
       "      <td>-0.314873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>1.322365</td>\n",
       "      <td>0.546677</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>-0.248840</td>\n",
       "      <td>-0.150393</td>\n",
       "      <td>0.735447</td>\n",
       "      <td>0.325228</td>\n",
       "      <td>1.086895</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>-0.320163</td>\n",
       "      <td>-0.432568</td>\n",
       "      <td>-0.057788</td>\n",
       "      <td>-0.473799</td>\n",
       "      <td>-0.574124</td>\n",
       "      <td>-0.678774</td>\n",
       "      <td>-0.491174</td>\n",
       "      <td>-0.595227</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2940 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  DailyRate  JobLevel  MonthlyIncome  MonthlyRate  \\\n",
       "0     0.446350   0.742527 -0.057788      -0.111264     0.726020   \n",
       "1     1.322365  -1.297775 -0.057788      -0.308160     1.488876   \n",
       "2     0.008343   1.414363 -0.961486      -1.001746    -1.674841   \n",
       "3    -0.429664   1.461466 -0.961486       0.610751     1.243211   \n",
       "4    -1.086676  -0.524295 -0.961486      -0.687351     0.325900   \n",
       "...        ...        ...       ...            ...          ...   \n",
       "2935 -0.101159   0.202082 -0.057788      -0.892005    -0.284329   \n",
       "2936  0.227347  -0.469754  0.845911       0.800894     1.004010   \n",
       "2937 -1.086676  -1.605183 -0.057788      -0.544025    -1.284418   \n",
       "2938  1.322365   0.546677 -0.057788      -0.248840    -0.150393   \n",
       "2939 -0.320163  -0.432568 -0.057788      -0.473799    -0.574124   \n",
       "\n",
       "      TotalWorkingYears  YearsAtCompany  YearsWithCurrManager  JobRole  \\\n",
       "0             -0.421642       -0.164613              0.245834      7.0   \n",
       "1             -0.164511        0.488508              0.806541      6.0   \n",
       "2             -0.550208       -1.144294             -1.155935      2.0   \n",
       "3             -0.421642        0.161947             -1.155935      6.0   \n",
       "4             -0.678774       -0.817734             -0.595227      2.0   \n",
       "...                 ...             ...                   ...      ...   \n",
       "2935           0.735447       -0.327893             -0.314873      2.0   \n",
       "2936          -0.293077       -0.001333              0.806541      0.0   \n",
       "2937          -0.678774       -0.164613             -0.314873      4.0   \n",
       "2938           0.735447        0.325228              1.086895      7.0   \n",
       "2939          -0.678774       -0.491174             -0.595227      2.0   \n",
       "\n",
       "      OverTime  \n",
       "0          1.0  \n",
       "1          0.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          0.0  \n",
       "...        ...  \n",
       "2935       0.0  \n",
       "2936       0.0  \n",
       "2937       1.0  \n",
       "2938       0.0  \n",
       "2939       0.0  \n",
       "\n",
       "[2940 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "kbest = SelectKBest(score_func = mutual_info_classif, k=10)\n",
    "X_final = kbest.fit_transform(X, y)\n",
    "\n",
    "X_final = pd.DataFrame(X_final)\n",
    "X_final.columns = X.columns[kbest.get_support()]\n",
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "electrical-exemption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Data Train : 2352\n",
      "Jumlah Data Test : 588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final,y, test_size=0.2, stratify = y)\n",
    "\n",
    "print(\"Jumlah Data Train : {0}\".format(len(X_train)))\n",
    "print(\"Jumlah Data Test : {0}\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f3656b-c845-4210-bcd3-590e5f054691",
   "metadata": {},
   "source": [
    "(2) Lakukan cross validation (k=4) menggunakan estimator logistic regression pada X_train_final dan y_train untuk menentukan hyperparameter 'penalty' yang optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89bfcc16-84f3-4458-aa3b-f67f7f54ba12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\hanun\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.8494898         nan 0.84991497 0.8494898\n",
      " 0.8494898  0.84906463 0.8494898  0.8494898         nan        nan\n",
      "        nan        nan        nan 0.84821429 0.84821429        nan\n",
      " 0.84821429 0.84821429]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=LogisticRegression(),\n",
       "             param_grid={'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'penalty':['l1', 'l2', 'elasticnet', 'none'],\n",
    "             'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "gscv = GridSearchCV(LogisticRegression(), param_grid, cv=4)\n",
    "\n",
    "gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "turned-protocol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l1', 'solver': 'saga'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param = gscv.best_params_\n",
    "best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b9a9d-d52e-4af6-b99a-635c3f020ee1",
   "metadata": {},
   "source": [
    "(3) Buat learning alg. dengan menggunakan penalty optimal. Fit trainset ke learning alg. ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1284f7dd-001c-4f38-b9dd-ac9351b11f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param['penalty']\n",
    "\n",
    "alg_optimal = LogisticRegression(penalty = best_param['penalty'],\n",
    "                                 solver = best_param['solver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "consistent-kingdom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_optimal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b7a65b-8d9a-4033-bb8c-6f46b859deed",
   "metadata": {},
   "source": [
    "(4) Plot ROC-AUC curve. Plot precision-recall curve (threshold pada axis-x, precision dan recall pada axis-y). Tentukan threshold optimal untuk model classifier yang telah Anda buat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d6c8d88-73f8-4776-842e-be1cac3e731d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "encouraging-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_df1 = pd.DataFrame(logreg_df)\n",
    "\n",
    "logreg_df1['recall'] = logreg_df1['TP']/(logreg_df1['TP']+logreg_df1['FN'])\n",
    "logreg_df1['precision'] = logreg_df1['TP']/(logreg_df1['TP']+logreg_df1['FP'])\n",
    "logreg_df1['fpr'] = logreg_df1['FP']/(logreg_df1['TN']+logreg_df1['TP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "under-donor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thre</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>379</td>\n",
       "      <td>1973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161139</td>\n",
       "      <td>5.205805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>360</td>\n",
       "      <td>1676</td>\n",
       "      <td>297</td>\n",
       "      <td>19</td>\n",
       "      <td>0.949868</td>\n",
       "      <td>0.176817</td>\n",
       "      <td>2.550989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>314</td>\n",
       "      <td>1081</td>\n",
       "      <td>892</td>\n",
       "      <td>65</td>\n",
       "      <td>0.828496</td>\n",
       "      <td>0.225090</td>\n",
       "      <td>0.896352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>259</td>\n",
       "      <td>675</td>\n",
       "      <td>1298</td>\n",
       "      <td>120</td>\n",
       "      <td>0.683377</td>\n",
       "      <td>0.277302</td>\n",
       "      <td>0.433526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>221</td>\n",
       "      <td>405</td>\n",
       "      <td>1568</td>\n",
       "      <td>158</td>\n",
       "      <td>0.583113</td>\n",
       "      <td>0.353035</td>\n",
       "      <td>0.226383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.25</td>\n",
       "      <td>192</td>\n",
       "      <td>270</td>\n",
       "      <td>1703</td>\n",
       "      <td>187</td>\n",
       "      <td>0.506596</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.142480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.30</td>\n",
       "      <td>153</td>\n",
       "      <td>194</td>\n",
       "      <td>1779</td>\n",
       "      <td>226</td>\n",
       "      <td>0.403694</td>\n",
       "      <td>0.440922</td>\n",
       "      <td>0.100414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.35</td>\n",
       "      <td>118</td>\n",
       "      <td>129</td>\n",
       "      <td>1844</td>\n",
       "      <td>261</td>\n",
       "      <td>0.311346</td>\n",
       "      <td>0.477733</td>\n",
       "      <td>0.065749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.40</td>\n",
       "      <td>88</td>\n",
       "      <td>92</td>\n",
       "      <td>1881</td>\n",
       "      <td>291</td>\n",
       "      <td>0.232190</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.046724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.45</td>\n",
       "      <td>66</td>\n",
       "      <td>39</td>\n",
       "      <td>1934</td>\n",
       "      <td>313</td>\n",
       "      <td>0.174142</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.50</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>1963</td>\n",
       "      <td>333</td>\n",
       "      <td>0.121372</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.004978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.55</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>1967</td>\n",
       "      <td>364</td>\n",
       "      <td>0.039578</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.003027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.60</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1973</td>\n",
       "      <td>374</td>\n",
       "      <td>0.013193</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    thre   TP    FP    TN   FN    recall  precision       fpr\n",
       "0   0.00  379  1973     0    0  1.000000   0.161139  5.205805\n",
       "1   0.05  360  1676   297   19  0.949868   0.176817  2.550989\n",
       "2   0.10  314  1081   892   65  0.828496   0.225090  0.896352\n",
       "3   0.15  259   675  1298  120  0.683377   0.277302  0.433526\n",
       "4   0.20  221   405  1568  158  0.583113   0.353035  0.226383\n",
       "5   0.25  192   270  1703  187  0.506596   0.415584  0.142480\n",
       "6   0.30  153   194  1779  226  0.403694   0.440922  0.100414\n",
       "7   0.35  118   129  1844  261  0.311346   0.477733  0.065749\n",
       "8   0.40   88    92  1881  291  0.232190   0.488889  0.046724\n",
       "9   0.45   66    39  1934  313  0.174142   0.628571  0.019500\n",
       "10  0.50   46    10  1963  333  0.121372   0.821429  0.004978\n",
       "11  0.55   15     6  1967  364  0.039578   0.714286  0.003027\n",
       "12  0.60    5     0  1973  374  0.013193   1.000000  0.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "close-dictionary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hanun\\venv\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, alg_optimal.predict_proba(X_train)[:,1])\n",
    "sns.lineplot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "appropriate-harbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.62473818, 0.62473818, 0.61946461, 0.61649707, 0.59854044,\n",
       "       0.59046137, 0.58972681, 0.58727178, 0.57745574, 0.5615877 ,\n",
       "       0.55762105, 0.55656457, 0.55211078, 0.55089012, 0.54492218,\n",
       "       0.54230924, 0.53665276, 0.53546738, 0.53131907, 0.53126212,\n",
       "       0.53064353, 0.52200993, 0.5212802 , 0.52098286, 0.51983647,\n",
       "       0.51038555, 0.50945569, 0.50694223, 0.50595436, 0.50509119,\n",
       "       0.50430565, 0.50391697, 0.50172562, 0.50133654, 0.49897272,\n",
       "       0.49558947, 0.49547574, 0.49302657, 0.4926853 , 0.48924655,\n",
       "       0.48924498, 0.48695551, 0.48492507, 0.47829105, 0.47399892,\n",
       "       0.47398811, 0.47241325, 0.46839409, 0.46701947, 0.46578788,\n",
       "       0.4651937 , 0.4614914 , 0.4601431 , 0.45969459, 0.45951334,\n",
       "       0.45907266, 0.45639633, 0.4554002 , 0.4553058 , 0.45527685,\n",
       "       0.45502938, 0.45394014, 0.45393359, 0.44489577, 0.44254578,\n",
       "       0.43828861, 0.43771049, 0.4361669 , 0.43515056, 0.43314983,\n",
       "       0.43094651, 0.4302705 , 0.42968129, 0.4295175 , 0.42776133,\n",
       "       0.42454478, 0.42317313, 0.42119364, 0.4204702 , 0.42001315,\n",
       "       0.41946862, 0.41939885, 0.419348  , 0.41723931, 0.41717355,\n",
       "       0.41562522, 0.41553715, 0.41465299, 0.4144529 , 0.41263059,\n",
       "       0.41259778, 0.40987482, 0.40974831, 0.4088837 , 0.40601831,\n",
       "       0.40447221, 0.40281046, 0.40063181, 0.39963619, 0.39943477,\n",
       "       0.39606473, 0.39517274, 0.39196669, 0.3903975 , 0.39017293,\n",
       "       0.38908472, 0.38841031, 0.38650438, 0.38422713, 0.38288064,\n",
       "       0.38065204, 0.38007595, 0.37973234, 0.3784433 , 0.377817  ,\n",
       "       0.37609953, 0.37267123, 0.37035845, 0.36987667, 0.36671168,\n",
       "       0.36466064, 0.36449254, 0.36429025, 0.36389385, 0.36168706,\n",
       "       0.36128742, 0.35960869, 0.35841741, 0.35813162, 0.35651931,\n",
       "       0.35605851, 0.35592282, 0.35529197, 0.35518758, 0.35093049,\n",
       "       0.35013646, 0.34990523, 0.34847402, 0.3484693 , 0.34733192,\n",
       "       0.3472059 , 0.34597828, 0.34423853, 0.34411814, 0.34216883,\n",
       "       0.3416939 , 0.34033204, 0.33931007, 0.33813651, 0.3370981 ,\n",
       "       0.33610828, 0.33546711, 0.33526663, 0.33496756, 0.33417342,\n",
       "       0.3338425 , 0.33202501, 0.32975056, 0.32970542, 0.32964107,\n",
       "       0.32900432, 0.32643078, 0.32608635, 0.32476939, 0.3243793 ,\n",
       "       0.3237929 , 0.32354019, 0.32172356, 0.31900533, 0.31750939,\n",
       "       0.31748634, 0.31706732, 0.31608592, 0.31606241, 0.31571899,\n",
       "       0.31553512, 0.31201931, 0.31123058, 0.31005838, 0.30929403,\n",
       "       0.30891195, 0.30809422, 0.30740704, 0.30615042, 0.30604922,\n",
       "       0.30560084, 0.30496394, 0.3048034 , 0.30437922, 0.30156768,\n",
       "       0.30021995, 0.29915409, 0.29890272, 0.29756324, 0.29753127,\n",
       "       0.29747785, 0.29731031, 0.29394641, 0.29349743, 0.29312884,\n",
       "       0.29299236, 0.29149756, 0.29117548, 0.28973157, 0.28939069,\n",
       "       0.28934004, 0.28481766, 0.28177778, 0.28121727, 0.27952401,\n",
       "       0.27920399, 0.2781087 , 0.27788462, 0.27614621, 0.27326713,\n",
       "       0.27312498, 0.27303337, 0.27177999, 0.27151689, 0.27013556,\n",
       "       0.27003817, 0.26952896, 0.26865706, 0.268253  , 0.26516045,\n",
       "       0.26297789, 0.26292927, 0.26269121, 0.26228326, 0.2591187 ,\n",
       "       0.25886264, 0.25880643, 0.25869583, 0.25850987, 0.25788324,\n",
       "       0.25747185, 0.25729761, 0.25461556, 0.2534502 , 0.25280529,\n",
       "       0.25259969, 0.25234374, 0.2519336 , 0.25152184, 0.25083159,\n",
       "       0.25077956, 0.2502142 , 0.24927349, 0.2483743 , 0.24702588,\n",
       "       0.24684936, 0.24668592, 0.24664803, 0.2461778 , 0.24583164,\n",
       "       0.24436039, 0.24434694, 0.24393047, 0.2435163 , 0.24234036,\n",
       "       0.2423214 , 0.24185099, 0.24141595, 0.24119882, 0.24040797,\n",
       "       0.23990818, 0.2389692 , 0.23857955, 0.23697808, 0.23697413,\n",
       "       0.23474794, 0.23442008, 0.23375751, 0.23295775, 0.23292562,\n",
       "       0.23184409, 0.23165998, 0.23060719, 0.22985399, 0.22906489,\n",
       "       0.22894951, 0.22487305, 0.22422891, 0.22409798, 0.22300734,\n",
       "       0.22284356, 0.22251995, 0.22212744, 0.22162681, 0.22080861,\n",
       "       0.22063937, 0.2163777 , 0.21584067, 0.21553377, 0.21415658,\n",
       "       0.21407212, 0.21317926, 0.21291219, 0.21193577, 0.21128474,\n",
       "       0.21048082, 0.21038279, 0.21026833, 0.21007339, 0.20974812,\n",
       "       0.20958639, 0.20955668, 0.20877652, 0.20869584, 0.20841233,\n",
       "       0.20816832, 0.20675989, 0.20646028, 0.20634243, 0.20620879,\n",
       "       0.20511544, 0.20507201, 0.20490601, 0.20367298, 0.2034522 ,\n",
       "       0.20333481, 0.20174235, 0.20058143, 0.19856579, 0.198312  ,\n",
       "       0.19709504, 0.19709411, 0.19678765, 0.1964877 , 0.19564018,\n",
       "       0.19556537, 0.195033  , 0.19492711, 0.1940226 , 0.19362738,\n",
       "       0.1929037 , 0.19265014, 0.19157701, 0.19150976, 0.1909525 ,\n",
       "       0.19087175, 0.19014724, 0.18980835, 0.18890975, 0.1888556 ,\n",
       "       0.18867469, 0.18863678, 0.1872752 , 0.18696185, 0.18680697,\n",
       "       0.18669617, 0.18609121, 0.18525366, 0.18509796, 0.18488581,\n",
       "       0.18446887, 0.18434439, 0.18354482, 0.18354252, 0.18274103,\n",
       "       0.18250171, 0.18236336, 0.18228925, 0.18168729, 0.18155315,\n",
       "       0.1808534 , 0.18071766, 0.18056735, 0.1804381 , 0.18024459,\n",
       "       0.18022607, 0.17994029, 0.17941767, 0.17832353, 0.17782675,\n",
       "       0.17657552, 0.17648172, 0.17595452, 0.17564639, 0.17492151,\n",
       "       0.17431566, 0.173708  , 0.17322698, 0.17211882, 0.17080913,\n",
       "       0.1706652 , 0.17026929, 0.16981126, 0.16974901, 0.16971032,\n",
       "       0.16953884, 0.16931845, 0.16877278, 0.1666688 , 0.16659144,\n",
       "       0.16656709, 0.16654372, 0.16614879, 0.16596225, 0.16596115,\n",
       "       0.16595193, 0.16566479, 0.16549805, 0.16536695, 0.16529076,\n",
       "       0.16488929, 0.16393675, 0.16325396, 0.16299876, 0.16274801,\n",
       "       0.16236538, 0.16233536, 0.16086204, 0.16022535, 0.15995116,\n",
       "       0.15974781, 0.15955143, 0.15928135, 0.15905138, 0.15874924,\n",
       "       0.1586172 , 0.15857148, 0.15826443, 0.15786657, 0.15784926,\n",
       "       0.15756802, 0.15748947, 0.15718044, 0.15666889, 0.15659126,\n",
       "       0.15551106, 0.15540592, 0.15527005, 0.15513642, 0.15489383,\n",
       "       0.15473837, 0.15342278, 0.15329467, 0.15322742, 0.15304837,\n",
       "       0.15303295, 0.15217851, 0.15216658, 0.151924  , 0.15162148,\n",
       "       0.15149112, 0.15145471, 0.15121921, 0.1512054 , 0.1510021 ,\n",
       "       0.15095209, 0.15087612, 0.15078142, 0.15021899, 0.15013604,\n",
       "       0.14983887, 0.14939243, 0.14850251, 0.14828756, 0.14762984,\n",
       "       0.14742332, 0.14706003, 0.14702752, 0.14647531, 0.14606188,\n",
       "       0.14549283, 0.14543328, 0.14537382, 0.14521105, 0.14476378,\n",
       "       0.14474995, 0.14409771, 0.14355862, 0.14336995, 0.14284985,\n",
       "       0.1427119 , 0.14256073, 0.14247663, 0.1417576 , 0.14170083,\n",
       "       0.14157327, 0.14124902, 0.14118123, 0.14093462, 0.1404099 ,\n",
       "       0.14032774, 0.13983732, 0.13979649, 0.13948326, 0.13916058,\n",
       "       0.13868134, 0.13747586, 0.13744934, 0.13722938, 0.13685327,\n",
       "       0.13655561, 0.13647856, 0.13612793, 0.1355482 , 0.13538248,\n",
       "       0.13505001, 0.13504138, 0.13449367, 0.13430894, 0.13371987,\n",
       "       0.13366678, 0.13347587, 0.13336158, 0.13274565, 0.13270463,\n",
       "       0.13255563, 0.1325063 , 0.13242217, 0.13193725, 0.13166265,\n",
       "       0.13132701, 0.13072313, 0.13033397, 0.13011337, 0.13010136,\n",
       "       0.13006103, 0.12997663, 0.12979769, 0.12965393, 0.12963504,\n",
       "       0.12960565, 0.12952807, 0.12925953, 0.12908497, 0.12901127,\n",
       "       0.12865336, 0.12847109, 0.12799218, 0.12788349, 0.1275541 ,\n",
       "       0.127554  , 0.1275072 , 0.12736791, 0.12712273, 0.12707011,\n",
       "       0.12672968, 0.12636594, 0.12582522, 0.12572015, 0.12567534,\n",
       "       0.12526562, 0.12477113, 0.12475183, 0.12432878, 0.12413117,\n",
       "       0.12401961, 0.12388705, 0.1238551 , 0.1235407 , 0.1235064 ,\n",
       "       0.12287522, 0.12282695, 0.12280489, 0.12254756, 0.12220048,\n",
       "       0.12155261, 0.12150025, 0.12108064, 0.12087869, 0.12078965,\n",
       "       0.12039024, 0.11990211, 0.11962822, 0.11865923, 0.11839602,\n",
       "       0.11832987, 0.1182973 , 0.11807663, 0.11791443, 0.11755158,\n",
       "       0.11744764, 0.11724308, 0.11720675, 0.11702153, 0.11701108,\n",
       "       0.11689952, 0.11559024, 0.1155895 , 0.115148  , 0.11513155,\n",
       "       0.11503288, 0.11480749, 0.11460673, 0.11438259, 0.11399869,\n",
       "       0.11243205, 0.11218961, 0.11162586, 0.11153047, 0.1111201 ,\n",
       "       0.11070208, 0.11060892, 0.11056979, 0.11041731, 0.11006283,\n",
       "       0.10996062, 0.10973583, 0.10972049, 0.10964342, 0.10916595,\n",
       "       0.10910717, 0.10851893, 0.10831165, 0.10813029, 0.108094  ,\n",
       "       0.10774743, 0.10731265, 0.10696186, 0.10676754, 0.10674951,\n",
       "       0.10642928, 0.10597737, 0.10568669, 0.10557936, 0.10541217,\n",
       "       0.10506767, 0.1046794 , 0.10458458, 0.10426467, 0.10415562,\n",
       "       0.10401426, 0.10384068, 0.10310747, 0.10292957, 0.10256217,\n",
       "       0.10179291, 0.10155009, 0.10132122, 0.10084069, 0.10079449,\n",
       "       0.10024033, 0.10016267, 0.10000039, 0.09999745, 0.09969838,\n",
       "       0.09969359, 0.09963311, 0.09958949, 0.09946869, 0.09924921,\n",
       "       0.09913415, 0.09884157, 0.09874008, 0.09868843, 0.09853516,\n",
       "       0.09842108, 0.09831972, 0.09692935, 0.09674945, 0.09668569,\n",
       "       0.09665356, 0.09660341, 0.09657961, 0.09653051, 0.09645166,\n",
       "       0.09626141, 0.09626115, 0.09587808, 0.09581119, 0.0955714 ,\n",
       "       0.09505011, 0.09504718, 0.09504334, 0.09504118, 0.09476293,\n",
       "       0.09469631, 0.09361504, 0.09343781, 0.09301364, 0.09284036,\n",
       "       0.092727  , 0.09264909, 0.09213043, 0.0918773 , 0.09185013,\n",
       "       0.09135994, 0.09056986, 0.08990999, 0.08869926, 0.0886027 ,\n",
       "       0.08846349, 0.08844069, 0.08836249, 0.08826506, 0.08780743,\n",
       "       0.08763823, 0.08757353, 0.08692399, 0.0868093 , 0.08668935,\n",
       "       0.08667246, 0.08603946, 0.08601822, 0.08583306, 0.08568464,\n",
       "       0.08565185, 0.0854819 , 0.08503758, 0.0847568 , 0.08470412,\n",
       "       0.08468306, 0.08447287, 0.08379581, 0.08339046, 0.08329444,\n",
       "       0.08315878, 0.08282474, 0.08273386, 0.0826785 , 0.08239766,\n",
       "       0.08234853, 0.08220589, 0.08211098, 0.08199722, 0.08072939,\n",
       "       0.08051803, 0.08043586, 0.08020991, 0.08016501, 0.08001053,\n",
       "       0.07999588, 0.07985346, 0.07981303, 0.07968602, 0.07941812,\n",
       "       0.07934894, 0.0792742 , 0.07927026, 0.07888637, 0.07864961,\n",
       "       0.07806562, 0.07793335, 0.07783989, 0.07779287, 0.07748106,\n",
       "       0.07747675, 0.07625179, 0.07624648, 0.07587162, 0.07587034,\n",
       "       0.07582553, 0.07551279, 0.07550984, 0.07544919, 0.07524485,\n",
       "       0.07517934, 0.07491505, 0.07468355, 0.07466716, 0.07332343,\n",
       "       0.07323457, 0.07318316, 0.07311409, 0.07238009, 0.0723591 ,\n",
       "       0.07205353, 0.07197713, 0.07185074, 0.07157859, 0.07127608,\n",
       "       0.07100422, 0.07034794, 0.07025753, 0.06994099, 0.06979884,\n",
       "       0.06941795, 0.06935627, 0.06922622, 0.06898148, 0.06884285,\n",
       "       0.06864665, 0.06844127, 0.06756253, 0.06752238, 0.06626655,\n",
       "       0.06619395, 0.0661482 , 0.06573257, 0.06510137, 0.06507004,\n",
       "       0.06503623, 0.0649428 , 0.06470056, 0.06455261, 0.06450773,\n",
       "       0.06430687, 0.06394872, 0.06346443, 0.06340772, 0.06316402,\n",
       "       0.0630784 , 0.06210517, 0.06204603, 0.06184645, 0.06180569,\n",
       "       0.0616894 , 0.06163461, 0.06132825, 0.06084742, 0.06056028,\n",
       "       0.06049489, 0.06024625, 0.06010959, 0.05968518, 0.059348  ,\n",
       "       0.05871651, 0.05820595, 0.05800661, 0.05784852, 0.05776296,\n",
       "       0.057748  , 0.05745428, 0.05731883, 0.05708511, 0.05705153,\n",
       "       0.05670694, 0.05658565, 0.05623784, 0.05604879, 0.05604804,\n",
       "       0.05594435, 0.05580264, 0.05567306, 0.05556575, 0.05548261,\n",
       "       0.05502606, 0.05480475, 0.05450939, 0.05447815, 0.05444785,\n",
       "       0.05444585, 0.05425829, 0.05417683, 0.05400697, 0.05368837,\n",
       "       0.05315181, 0.05313783, 0.05310658, 0.05272687, 0.0526518 ,\n",
       "       0.05251508, 0.05230889, 0.05209572, 0.05186818, 0.05174455,\n",
       "       0.05161242, 0.05141925, 0.05116657, 0.05110486, 0.05037339,\n",
       "       0.05033298, 0.05020974, 0.05009304, 0.04923553, 0.04922102,\n",
       "       0.0486455 , 0.04850891, 0.04836349, 0.04825312, 0.04787328,\n",
       "       0.0476698 , 0.04741783, 0.04731464, 0.04719579, 0.04670715,\n",
       "       0.04663375, 0.04655266, 0.0465414 , 0.04624975, 0.04613849,\n",
       "       0.04607701, 0.04578104, 0.04574905, 0.04557639, 0.04554984,\n",
       "       0.0454242 , 0.04533644, 0.04510274, 0.04498847, 0.04494322,\n",
       "       0.04482083, 0.04419286, 0.04390913, 0.04234977, 0.04220219,\n",
       "       0.0418147 , 0.041761  , 0.04151359, 0.04144643, 0.04140361,\n",
       "       0.04137984, 0.04076145, 0.04047456, 0.04032883, 0.04031237,\n",
       "       0.03993719, 0.03989786, 0.03989078, 0.03984255, 0.03960651,\n",
       "       0.0388348 , 0.03875232, 0.03869235, 0.03841808, 0.038304  ,\n",
       "       0.03820716, 0.03748928, 0.03723631, 0.03714691, 0.03714061,\n",
       "       0.03697563, 0.03677125, 0.03652676, 0.03604786, 0.03539477,\n",
       "       0.03538044, 0.03526495, 0.03517053, 0.0346973 , 0.03454446,\n",
       "       0.03421713, 0.03373752, 0.03372318, 0.03276625, 0.03271164,\n",
       "       0.03240894, 0.03207622, 0.03169196, 0.03162895, 0.03110708,\n",
       "       0.03004294, 0.03000379, 0.02983224, 0.02977087, 0.02964037,\n",
       "       0.02954668, 0.02791744, 0.02771447, 0.02696471, 0.02661424,\n",
       "       0.02656888, 0.02653392, 0.02639115, 0.02633633, 0.02565893,\n",
       "       0.02562176, 0.02523728, 0.02523383, 0.02517602, 0.02511317,\n",
       "       0.02458274, 0.02442382, 0.02436832, 0.02342083, 0.02277725,\n",
       "       0.02268759, 0.02242207, 0.02239031, 0.02103423, 0.02096592,\n",
       "       0.01946287, 0.01944714, 0.01914026, 0.01891307, 0.01851337,\n",
       "       0.01760534, 0.01660956, 0.01658732, 0.014221  , 0.01383497,\n",
       "       0.01347405, 0.0134559 , 0.01209672, 0.01158676, 0.00943629,\n",
       "       0.00851996, 0.00634812])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c98f9a-f2c5-4eb9-807b-0943bbcfa72d",
   "metadata": {},
   "source": [
    "(5) Hitung performance model Anda dengan menggunakan trainset dan testset:roc-auc-score, recall, precision, dan fpr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "imperial-motivation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasil roc auc score train set : 0.7366907071320343\n",
      "hasil roc auc score test set : 0.7681221308850218\n"
     ]
    }
   ],
   "source": [
    "#roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"hasil roc auc score train set : {}\".format(roc_auc_score(y_train, alg_optimal.predict_proba(X_train)[:,1])))\n",
    "print(\"hasil roc auc score test set : {}\".format(roc_auc_score(y_test, alg_optimal.predict_proba(X_test)[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dedicated-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = alg_optimal.predict(X_test)\n",
    "x_pred = alg_optimal.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8daa246-da77-4124-98eb-b17a958e2aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasil recall score train set : 0.8541666666666666\n",
      "hasil recall score test set : 0.8554421768707483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(\"hasil recall score train set : {}\".format(recall_score(y_train, x_pred, average='weighted')))\n",
    "print(\"hasil recall score test set : {}\".format(recall_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "alien-tradition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasil precision score train set : 0.8495610896797744\n",
      "hasil precision score test set : 0.8642644557823128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(\"hasil precision score train set : {}\".format(precision_score(y_train, x_pred, average='weighted')))\n",
    "print(\"hasil precision score test set : {}\".format(precision_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ddd155d-b59c-4730-b40e-dea645ddb722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasil fpr score train: 0.4205067804360909\n",
      "hasil fpr score test: 0.3380975272309443\n"
     ]
    }
   ],
   "source": [
    "fpr2, tpr2, threshold2 = roc_curve(y_test, alg_optimal.predict_proba(X_test)[:,1])\n",
    "\n",
    "print(\"hasil fpr score train: {}\".format(fpr.mean()))\n",
    "print(\"hasil fpr score test: {}\".format(fpr2.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6509a2-bab1-47af-abc1-23b01639df60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
